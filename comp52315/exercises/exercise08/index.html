<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Simple loop tiling for matrix-matrix multiplication #  Having looked at the effect of loop tiling schemes for increasing the throughput of matrix transpose operations in exercise 7, we&rsquo;re now going to look at throughput of the loop-tiling scheme presented in lectures for matrix-matrix multiplication. I provide an implementation of matrix-matrix multiplication that provides three different variants. A naive triple loop, a tiled version of the triple loop, and a tiled version that manually packs local buffers."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Exercise 8: loop tiling matrix-matrix multiplication"><meta property="og:description" content="Simple loop tiling for matrix-matrix multiplication #  Having looked at the effect of loop tiling schemes for increasing the throughput of matrix transpose operations in exercise 7, we&rsquo;re now going to look at throughput of the loop-tiling scheme presented in lectures for matrix-matrix multiplication. I provide an implementation of matrix-matrix multiplication that provides three different variants. A naive triple loop, a tiled version of the triple loop, and a tiled version that manually packs local buffers."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/comp52315/exercises/exercise08/"><meta property="article:modified_time" content="2020-11-18T19:14:07+00:00"><title>Exercise 8: loop tiling matrix-matrix multiplication | COMP52315 – Performance Engineering</title><link rel=manifest href=/comp52315/manifest.json><link rel=icon href=/comp52315/favicon.png type=image/x-icon><link rel=stylesheet href=/comp52315/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/comp52315/logo.svg alt=Logo><h2><a href=/comp52315>COMP52315 – Performance Engineering</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/comp52315/setup/contact/>Contact details</a></li><li><a href=/comp52315/setup/hamilton/>Hamilton accounts</a></li><li><a href=/comp52315/setup/configuration/>ssh configuration</a></li><li><a href=/comp52315/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/comp52315/exercises/exercise01/>Exercise 1: sum reductions</a></li><li><a href=/comp52315/exercises/exercise02/>Exercise 2: caches</a></li><li><a href=/comp52315/exercises/exercise03/>Exercise 3: memory bandwidth</a></li><li><a href=/comp52315/exercises/exercise04/>Exercise 4: roofline analysis</a></li><li><a href=/comp52315/exercises/exercise05/>Exercise 5: models and measurements</a></li><li><a href=/comp52315/exercises/exercise06/>Exercise 6: profiling</a></li><li><a href=/comp52315/exercises/exercise07/>Exercise 7: loop tiling matrix transpose</a></li><li><a href=/comp52315/exercises/exercise08/ class=active>Exercise 8: loop tiling matrix-matrix multiplication</a></li><li><a href=/comp52315/exercises/exercise09/>Exercise 9: compiler feedback</a></li><li><a href=/comp52315/exercises/exercise10/>Exercise 10: stencil layer conditions</a></li></ul></li><li><span>Notes</span><ul><li><a href=/comp52315/notes/introduction/>Introduction</a></li><li><a href=/comp52315/notes/memory/>The memory hierarchy</a></li><li><a href=/comp52315/notes/roofline/>Performance models: roofline</a></li></ul></li><li><a href=/comp52315/coursework/>Coursework: fast finite elements</a><ul></ul></li><li><a href=/comp52315/acknowledgements/>Acknowledgements & further reading</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/comp52315/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Exercise 8: loop tiling matrix-matrix multiplication</strong>
<label for=toc-control></label></div></header><article class=markdown><h1 id=simple-loop-tiling-for-matrix-matrix-multiplication>Simple loop tiling for matrix-matrix multiplication
<a class=anchor href=#simple-loop-tiling-for-matrix-matrix-multiplication>#</a></h1><p>Having looked at the effect of loop tiling schemes for increasing the
throughput of matrix transpose operations in <a href=https://teaching.wence.uk/comp52315/exercises/exercise07/>exercise 7</a>, we&rsquo;re now going to look at throughput of the
loop-tiling scheme presented in lectures for matrix-matrix
multiplication. I provide an implementation of <a href=https://teaching.wence.uk/code/exercise08/gemm.c>matrix-matrix
multiplication</a> that provides three
different variants. A naive triple loop, a tiled version of the triple
loop, and a tiled version that manually packs local buffers.</p><h2 id=compiling-the-code>Compiling the code
<a class=anchor href=#compiling-the-code>#</a></h2><p>We&rsquo;ll use the intel compiler to build this code. So after logging in
to Hamilton and downloading, load the relevant modules</p><pre><code>module load gcc/8.2.0
module load intel/2019.5
</code></pre><p>The code can be compiled with <code>icc -O3 -xHOST -o gemm gemm.c</code>.</p><h2 id=compare-the-variants>Compare the variants
<a class=anchor href=#compare-the-variants>#</a></h2><p>You can run the different implemented variants with <code>./gemm N VARIANT</code>
where <code>N</code> is the matrix size and <code>VARIANT</code> is one of <code>BASIC</code>, <code>TILED</code>,
or <code>TILEDPACKED</code>.</p><p>For the <code>TILED</code> and <code>TILEDPACKED</code> variants, the matrix size must be a
multiple of the tile size (which is 64 by default).</p><blockquote class=task><h3>Task</h3><p>Run the code with matrix sizes from 64 up to 2048.</p></blockquote><blockquote class=question><h3>Question</h3><p>Which version performs the best?</p></blockquote><h2 id=inspecting-optimisation-reports>Inspecting optimisation reports
<a class=anchor href=#inspecting-optimisation-reports>#</a></h2><p>You probably noticed that the <code>TILEDPACKED</code> variant
performed very badly. Before measuring anything, we can look at more
detailed output from the compiler to see if we spot anything
suspicious.</p><p>The Intel compiler can provide excellent diagnostics on what it was
doing when compiling code. Run the compile command again, this time
with <code>icc -O3 -xHOST -qopt-report=5 -qopt-report-file=no-simd-reduction.txt -o gemm gemm.c</code>. Look in the
resulting <code>no-simd-reduction.txt</code> file and search for
<code>tiled_packed_gemm</code> (the name of the routine that performs worse than
expected).</p><blockquote class=question><h3>Question</h3><p>Do you see anything in the optimisation report that stands out as
interesting?</p></blockquote><p>In this case, it seems that we need to give the compiler a hint as to
how to proceed. It did not vectorise the inner loop because it
couldn&rsquo;t prove that it was safe to do so. However, we know it is safe,
so I&rsquo;ve added some annotations to the relevant loop. Instead of having</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>p</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>p</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>TILESIZE</span><span style=color:#111>;</span> <span style=color:#111>p</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
  <span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>j_</span><span style=color:#f92672>*</span><span style=color:#111>ldc</span> <span style=color:#f92672>+</span> <span style=color:#111>i_</span><span style=color:#111>]</span> <span style=color:#f92672>+=</span> <span style=color:#111>apack</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>bpack</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
</code></pre></div><p>I use <a href=https://www.openmp.org>OpenMP</a> pragma annotations to instruct
the compiler to vectorise the loop</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>double</span> <span style=color:#111>c_</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span>
<span style=color:#75715e>#pragma omp simd reduction (+: c_)
</span><span style=color:#75715e></span><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>p</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>p</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>TILESIZE</span><span style=color:#111>;</span> <span style=color:#111>p</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
  <span style=color:#111>c_</span> <span style=color:#f92672>+=</span> <span style=color:#111>apack</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>]</span> <span style=color:#f92672>*</span> <span style=color:#111>bpack</span><span style=color:#111>[</span><span style=color:#111>j</span><span style=color:#f92672>*</span><span style=color:#111>TILESIZE</span> <span style=color:#f92672>+</span> <span style=color:#111>p</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
<span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>j_</span><span style=color:#f92672>*</span><span style=color:#111>ldc</span> <span style=color:#f92672>+</span> <span style=color:#111>i_</span><span style=color:#111>]</span> <span style=color:#f92672>+=</span> <span style=color:#111>c_</span><span style=color:#111>;</span>
</code></pre></div><blockquote class=task><h3>Task</h3><p>Try compiling again, this time adding <code>-DSIMD_REDUCTION</code> to the
compile line (and changing the output file for the optimisation report
to <code>simd-reduction.txt</code></p></blockquote><blockquote class=question><h3>Question</h3><p><p>Look at the new optimisation report and see what the compiler reports
this time.</p><p>Did it manage to vectorise the loop?</p></p></blockquote><blockquote class=task><h3>Task</h3><p>Benchmark this new version of the <code>TILEDPACKED</code> variant using the same
set of matrix sizes as before.</p></blockquote><blockquote class=question><h3>Question</h3><p>Do you observe any change in the performance?</p></blockquote><h2 id=the-effects-of-tiling-on-memopry-movement>The effects of tiling on memopry movement
<a class=anchor href=#the-effects-of-tiling-on-memopry-movement>#</a></h2><p>As usual, this example is also annotated with likwid markers. We&rsquo;ll
use <code>likwid-perfctr</code> to measure the effect of loop tiling on the total
<em>data movement</em> and measured <em>arithmetic intensity</em> for a large
matrix. We&rsquo;ll need to recompile with likwid enabled for this, so
<code>module load likwid/5.0.1</code> and recompile, adding <code>-DLIKWID_PERFMON -llikwid</code> to the compilation flags.</p><blockquote class=task><h3>Task</h3><p>Measure the memory and floating point performance for the three
different variatnts using \(N = 3072\) using the <code>MEM_DP</code> group.</p></blockquote><blockquote class=question><h3>Question</h3><p><p>What do you observe in terms of arithmetic intensity and the total
volume of data moved from main memory?</p><p>Can you relate this to the simple model we set up in lectures?</p></p></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/commit/6abf1d2c7f3111ce070650b8e953a796186a496c title="Last modified by Lawrence Mitchell | November 18, 2020" target=_blank rel=noopener><img src=/comp52315/svg/calendar.svg class=book-icon alt=Calendar>
<span>November 18, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/edit/main/site/content//exercises/exercise08.md target=_blank rel=noopener><img src=/comp52315/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a> and <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/comp52315/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div></main></body></html>