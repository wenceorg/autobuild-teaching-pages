<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="An overview of memory hierarchies #  Reduction benchmark #  In exercise 1 you looked at the performance of a vectorised and non-vectorised version of a very simple loop computing the sum of an array of floating point numbers.
In doing so, you produced a plot of the performance (in terms of floating point throughput) as a function of array size. You should have observed something similar to that shown here."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="The memory hierarchy"><meta property="og:description" content="An overview of memory hierarchies #  Reduction benchmark #  In exercise 1 you looked at the performance of a vectorised and non-vectorised version of a very simple loop computing the sum of an array of floating point numbers.
In doing so, you produced a plot of the performance (in terms of floating point throughput) as a function of array size. You should have observed something similar to that shown here."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/comp52315/notes/memory/"><meta property="article:modified_time" content="2020-07-15T17:39:48+01:00"><title>The memory hierarchy | COMP52315 – Performance Engineering</title><link rel=manifest href=/comp52315/manifest.json><link rel=icon href=/comp52315/favicon.png type=image/x-icon><link rel=stylesheet href=/comp52315/book.min.261e720bffd3316eb0a469b3b9ac30b593d2c67c402d94c5642cdf86c8d499b4.css integrity="sha256-Jh5yC//TMW6wpGmzuawwtZPSxnxALZTFZCzfhsjUmbQ="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body);></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/comp52315><span>COMP52315 – Performance Engineering</span></a></h2><ul><li><span>Administrivia</span><ul><li><a href=/comp52315/setup/contact/>Contact details</a></li><li><a href=/comp52315/setup/hamilton/>Hamilton accounts</a></li><li><a href=/comp52315/setup/configuration/>ssh configuration</a></li><li><a href=/comp52315/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/comp52315/exercises/exercise01/>Exercise 1: sum reductions</a></li><li><a href=/comp52315/exercises/exercise02/>Exercise 2: caches</a></li><li><a href=/comp52315/exercises/exercise03/>Exercise 3: memory bandwidth</a></li><li><a href=/comp52315/exercises/exercise04/>Exercise 4: roofline analysis</a></li><li><a href=/comp52315/exercises/exercise05/>Exercise 5: models and measurements</a></li><li><a href=/comp52315/exercises/exercise06/>Exercise 6: profiling</a></li><li><a href=/comp52315/exercises/exercise07/>Exercise 7: loop tiling matrix transpose</a></li><li><a href=/comp52315/exercises/exercise08/>Exercise 8: loop tiling matrix-matrix multiplication</a></li><li><a href=/comp52315/exercises/exercise09/>Exercise 9: compiler feedback</a></li><li><a href=/comp52315/exercises/exercise10/>Exercise 10: stencil layer conditions</a></li></ul></li><li><span>Notes</span><ul><li><a href=/comp52315/notes/introduction/>Introduction</a></li><li><a href=/comp52315/notes/memory/ class=active>The memory hierarchy</a></li></ul></li><li><a href=/comp52315/acknowledgements/>Acknowledgements</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/comp52315/svg/menu.svg class=book-icon alt=Menu></label>
<strong>The memory hierarchy</strong>
<label for=toc-control><img src=/comp52315/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#reduction-benchmark>Reduction benchmark</a></li><li><a href=#memory-hierarchy>Memory hierarchy</a></li><li><a href=#caches>Caches</a></li><li><a href=#measurement>Measurement</a></li><li><a href=#a-predictive-model-for-reductions>A predictive model for reductions</a><ul><li><a href=#l1-bandwidth>L1 bandwidth</a></li><li><a href=#l2-bandwidth>L2 bandwidth</a></li><li><a href=#l3-and-main-memory-bandwidth>L3 and main memory bandwidth</a></li></ul></li><li><a href=#stepping-back>Stepping back</a></li><li><a href=#scalable-and-saturating-resources>Scalable and saturating resources</a></li></ul></nav></aside></header><article class=markdown><h1 id=an-overview-of-memory-hierarchies>An overview of memory hierarchies
<a class=anchor href=#an-overview-of-memory-hierarchies>#</a></h1><h2 id=reduction-benchmark>Reduction benchmark
<a class=anchor href=#reduction-benchmark>#</a></h2><p>In <a href=https://teaching.wence.uk/comp52315/exercises/exercise01/>exercise 1</a> you looked at the
performance of a vectorised and non-vectorised version of a very
simple loop computing the sum of an array of floating point numbers.</p><p>In doing so, you produced a plot of the performance (in terms of
floating point throughput) as a function of array size. You should
have observed something similar to that shown here.</p><p>FIXME: add figure</p><p>We see that the <abbr title="Single Instruction Multiple
Data">SIMD</abbr> (vectorised) code has four distinct performance
plateaus as a function of the array size, whereas the scalar code has
only two.</p><p>On this hardware (Broadwell), the chip can issue up to one <code>ADD</code>
(scalar or vector) per cycle. The peak clock speed is 2.9GHz. So the
peak scalar throughput of addition is 2.9GFlops/s, while the peak
vector throughput is \(2.9 \times 8 = 23.2\)GFlops/s.</p><p>We can see that the vector code achieves peak throughput for small
vectors, but not large ones. Why is this?</p><p>Remember that as well as thinking about the <a href=https://teaching.wence.uk/comp52315/notes/introduction/#resource-bottleneck-instruction-throughput>primary resource</a> of
instruction throughput, we also need to consider whether <a href=https://teaching.wence.uk/comp52315/notes/introduction/#resource-bottleneck-data-transfers>data
transfers</a> are
producing the bottleneck. For this, we need to consider the memory
hierarchy.</p><h2 id=memory-hierarchy>Memory hierarchy
<a class=anchor href=#memory-hierarchy>#</a></h2><p>In the von Neumann model, program code and data must be transferred
from memory to the CPU (and back again). To speed up computation we can
increase the speed at which instructions execute. We can also reduce
the time it takes to <em>move</em> data between the memory and the CPU.</p><p>In an ideal world, to process lots of data very fast, we would have
<em>large</em> (in terms of storage) and <em>fast</em> (in terms of transfer speed)
memory. Unfortunately, physics gets in the way, and we can pick one of</p><ol><li><em>small</em> and <em>fast</em></li><li><em>large</em> and <em>slow</em></li></ol><p>In fact, there is a sliding scale here, as we make the storage
capacity smaller we can make the memory faster, and vice versa.</p><p>We have something close to the following picture</p><p>FIXME add figure</p><p>To explore these latencies in more depth (and see how they&rsquo;ve changed
over time), see <a href=https://colin-scott.github.io/personal_website/research/interactive_latency.html>latency numbers every programmer should
know</a></p><h2 id=caches>Caches
<a class=anchor href=#caches>#</a></h2><p>Having identified the high level problem that we can&rsquo;t make large,
fast memory, what can chip designers do about it? The answer (on CPUs
at least) is <em>caches</em>.</p><p>The idea is that we add a hierarchy of small, fast memory. These keep
a copy of <em>frequently used</em> data and are used to speed up access.
Except in certain special cases, it&rsquo;s not possible to know <em>which</em>
data will be used frequently. As a consequence, caches rely on a
<em>principle of locality</em>.</p><p>FIXME: add details on caches</p><h2 id=measurement>Measurement
<a class=anchor href=#measurement>#</a></h2><p>As well as using
<a href=https://github.com/RRZE-HPC/likwid/wiki/Likwid-Bench>likwid-bench</a>
to measure floating point throughput of some simple loops, we can also
use it to measure memory bandwidth. In <a href=https://teaching.wence.uk/comp52315/exercises/exercise02/>exercise 2</a> you should do this to determine the cache
and main memory bandwidth on the Hamilton cores. We will use this to
construct a predictive model of the floating point throughput of the
reduction from <a href=https://teaching.wence.uk/comp52315/exercises/exercise01/>exercise 1</a>.</p><p>FIXME: add results</p><h2 id=a-predictive-model-for-reductions>A predictive model for reductions
<a class=anchor href=#a-predictive-model-for-reductions>#</a></h2><p>Let us remind ourselves of the code we want to predict the performance
of</p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><h4 id=c-code>C code</h4><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>float</span> <span style=color:#75af00>reduce</span><span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>N</span><span style=color:#111>,</span> 
    <span style=color:#00a8c8>const</span> <span style=color:#00a8c8>double</span> <span style=color:#f92672>*</span><span style=color:#00a8c8>restrict</span> <span style=color:#111>a</span><span style=color:#111>)</span>
<span style=color:#111>{</span>
  <span style=color:#00a8c8>float</span> <span style=color:#111>c</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
    <span style=color:#111>c</span> <span style=color:#f92672>+=</span> <span style=color:#111>a</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>];</span>
  <span style=color:#00a8c8>return</span> <span style=color:#111>c</span><span style=color:#111>;</span>
<span style=color:#111>}</span>
</code></pre></div></div><div class="flex-even markdown-inner"><h4 id=vectorised-pseudo-assembly>Vectorised pseudo-assembly</h4><pre><code>LOAD [r1.0, ..., r1.7] ← 0
i ← 0
loop:
  LOAD [r2.0, ..., r2.7] ← [a[i], ..., a[i+7]]
  ADD r1 ← r1 + r2 ; SIMD ADD
  i ← i + 8
  if i &lt; N: loop
result ← r1.0 + r1.1 + ... + r1.7
</code></pre></div></div><p>The accumulation parameter <code>c</code> is held in a register. At each
iteration of the vectorised loop, we load eight elements of <code>a</code> into a
recond register. Since each <code>float</code> value takes 4 bytes, this means
that each iteration of the loop requires 32 bytes of data.</p><p>Recall that we can run one <code>ADD</code> per cycle. To keep up with the
addition, the memory movement must therefore deliver 32 bytes/cycle.</p><p>At 2.9GHz, this translates to a sustained load bandwidth of</p><p>$$
32 \text{bytes/cycle} \times 2.9 \times 10^9 \text{cycle/s} = 92.8\text{Gbyte/s}.
$$</p><p>Let&rsquo;s match this up with our measurements.</p><h3 id=l1-bandwidth>L1 bandwidth
<a class=anchor href=#l1-bandwidth>#</a></h3><p>The smallest (and fastest) cache is the level one (or L1) cache. On
this hardware, we observe a sustained load bandwidth of around
300Gbyte/s. Hence, when the data fit in L1 (less than 32KB), the speed
of executing the <code>ADD</code> instruction is the limit.</p><h3 id=l2-bandwidth>L2 bandwidth
<a class=anchor href=#l2-bandwidth>#</a></h3><p>The next level of cache is level two (L2). This provides around
80Gbyte/s or 27bytes/cycle. Since \( 27 &lt; 32 \), we can&rsquo;t reach the
floating point peak when the data fit in L2. The best we can hope for
is</p><p>$$
2.9 \times 8 \times \frac{27}{32} = 19.6\text{GFlops/s}.
$$</p><h3 id=l3-and-main-memory-bandwidth>L3 and main memory bandwidth
<a class=anchor href=#l3-and-main-memory-bandwidth>#</a></h3><p>We apply the same idea to the level three (L3) cache and main memory.
L3 provides around 36Gbyte/s or 12bytes/cycle. We obtain an upper
limit of</p><p>$$
2.9 \times 8 \times \frac{12}{32} = 8.7\text{GFlops/s}
$$</p><p>For main memory, the memory bandwidth is around 13Gbyte/s or
4.5bytes/cycle, and the peak is approximately 3.25GFlops/s.</p><p>Let&rsquo;s redraw our floating point throughput graph, this time annotating
it with these predicted performance limits.</p><p>We can see that this simple model does a pretty good job of predicting
the performance of our test code.</p><h2 id=stepping-back>Stepping back
<a class=anchor href=#stepping-back>#</a></h2><p>This idea of predicting performance based on resource limits is a
powerful one, and we will return to it through the rest of the course.</p><p>As a practice, see if you can come up with throughput limits for the
following piece of code</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>void</span> <span style=color:#75af00>stream_triad</span><span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>N</span><span style=color:#111>,</span> <span style=color:#00a8c8>float</span> <span style=color:#f92672>*</span> <span style=color:#00a8c8>restrict</span> <span style=color:#111>a</span><span style=color:#111>,</span>
                  <span style=color:#00a8c8>const</span> <span style=color:#00a8c8>float</span> <span style=color:#f92672>*</span> <span style=color:#00a8c8>restrict</span> <span style=color:#111>b</span><span style=color:#111>,</span>
                  <span style=color:#00a8c8>const</span> <span style=color:#00a8c8>float</span> <span style=color:#f92672>*</span> <span style=color:#00a8c8>restrict</span> <span style=color:#111>c</span><span style=color:#111>,</span>
                  <span style=color:#00a8c8>const</span> <span style=color:#00a8c8>float</span> <span style=color:#111>alpha</span><span style=color:#111>)</span>
<span style=color:#111>{</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span>
    <span style=color:#111>a</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#111>b</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]</span><span style=color:#f92672>*</span><span style=color:#111>alpha</span> <span style=color:#f92672>+</span> <span style=color:#111>c</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>];</span>
<span style=color:#111>}</span>
</code></pre></div><p>The Broadwell chips on Hamilton can execute up to two loads and one
store per cycle. To determine the floating point limit (assuming no
memory constraints) note that this operation perfectly matches a
&ldquo;fused multiply add&rdquo;</p><pre><code>a_i ← b_i * alpha + c_i
</code></pre><p>Which is implemented as a single instruction <code>FMA</code>. Broadwell chips
can execute up to two <code>FMA</code> instructions per cycle.</p><p>We will revisit this in a later exercise.</p><h2 id=scalable-and-saturating-resources>Scalable and saturating resources
<a class=anchor href=#scalable-and-saturating-resources>#</a></h2><p>Although most of the focus in this course is on single core
performance, it is worthwhile taking a little time to consider how
resource use changes when we involve more cores. All modern chips have
more than one core on them.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/commit/a2761459d0d001202a8967931d8cad7da863f62f title="Last modified by Lawrence Mitchell | July 15, 2020" target=_blank rel=noopener><img src=/comp52315/svg/calendar.svg class=book-icon alt=Calendar>
<span>July 15, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/comp52315/edit/master/content//notes/memory.md target=_blank rel=noopener><img src=/comp52315/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>Copyright 2020&ndash;
<a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>
& <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by-sa/4.0/88x31.png></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#reduction-benchmark>Reduction benchmark</a></li><li><a href=#memory-hierarchy>Memory hierarchy</a></li><li><a href=#caches>Caches</a></li><li><a href=#measurement>Measurement</a></li><li><a href=#a-predictive-model-for-reductions>A predictive model for reductions</a><ul><li><a href=#l1-bandwidth>L1 bandwidth</a></li><li><a href=#l2-bandwidth>L2 bandwidth</a></li><li><a href=#l3-and-main-memory-bandwidth>L3 and main memory bandwidth</a></li></ul></li><li><a href=#stepping-back>Stepping back</a></li><li><a href=#scalable-and-saturating-resources>Scalable and saturating resources</a></li></ul></nav></aside></main></body></html>