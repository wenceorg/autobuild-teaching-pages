<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="OpenMP loop parallelism #  With a parallel region and identification of individual threads, we can actually parallelise loops &ldquo;by hand&rdquo;.
Suppose we wish to divide a loop approximately equally between all the threads, by assigning consecutive blocks of the loop iterations to consecutive threads.
 Distribution of 16 loop iterations across five threads.
  Notice here that the number of iterations is not evenly divisible by the number of threads, so we&rsquo;ve assigned one extra iteration to thread0."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Loop parallelism"><meta property="og:description" content="OpenMP loop parallelism #  With a parallel region and identification of individual threads, we can actually parallelise loops &ldquo;by hand&rdquo;.
Suppose we wish to divide a loop approximately equally between all the threads, by assigning consecutive blocks of the loop iterations to consecutive threads.
 Distribution of 16 loop iterations across five threads.
  Notice here that the number of iterations is not evenly divisible by the number of threads, so we&rsquo;ve assigned one extra iteration to thread0."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/phys52015/notes/openmp/loop-parallelism/"><meta property="article:modified_time" content="2020-10-28T10:40:33+00:00"><title>Loop parallelism | PHYS52015 – Introduction to HPC</title><link rel=manifest href=/phys52015/manifest.json><link rel=icon href=/phys52015/favicon.png type=image/x-icon><link rel=stylesheet href=/phys52015/book.min.bf7f3e732f1a68bc04f2ce50cc8c8a462404f04066d1e404f002f2914662d55d.css integrity="sha256-v38+cy8aaLwE8s5QzIyKRiQE8EBm0eQE8ALykUZi1V0="></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/phys52015/logo.svg alt=Logo><h2><a href=/phys52015>PHYS52015 – Introduction to HPC</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/phys52015/setup/hamilton-quickstart/>Hamilton access & quickstart</a></li><li><a href=/phys52015/setup/byod/>Local setup</a></li><li><a href=/phys52015/setup/configuration/>ssh configuration</a></li><li><a href=/phys52015/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/phys52015/exercises/hello/>Parallel Hello World</a></li><li><a href=/phys52015/exercises/vectorisation-loop/>Vectorisation: loops with conditionals</a></li><li><a href=/phys52015/exercises/vectorisation-stencil/>Vectorisation: stencils</a></li><li><a href=/phys52015/exercises/openmp-loop/>OpenMP: parallel loops</a></li><li><a href=/phys52015/exercises/openmp-stencil/>OpenMP: stencils & profiling</a></li><li><a href=/phys52015/exercises/mpi-pi/>MPI: Calculating π</a></li><li><a href=/phys52015/exercises/mpi-stencil/>MPI: halo exchanges</a></li></ul></li><li><span>Notes</span><ul><li><a href=/phys52015/notes/introduction/>Introduction and motivation</a></li><li><span>Theory & concepts</span><ul><li><a href=/phys52015/notes/theory/scaling-laws/>Parallel scaling laws</a></li><li><a href=/phys52015/notes/theory/hardware-parallelism/>Parallelism in hardware: an overview</a></li><li><a href=/phys52015/notes/theory/concepts/>Parallel patterns</a></li></ul></li><li><a href=/phys52015/notes/vectorisation/>Vectorisation</a><ul><li><a href=/phys52015/notes/vectorisation/compiler/>Compiler autovectorisation</a></li></ul></li><li><a href=/phys52015/notes/openmp/>OpenMP</a><ul><li><a href=/phys52015/notes/openmp/intro/>What is OpenMP?</a></li><li><a href=/phys52015/notes/openmp/loop-parallelism/ class=active>Loop parallelism</a></li><li><a href=/phys52015/notes/openmp/collectives/>Collectives</a></li><li><a href=/phys52015/notes/openmp/tasks/>Task parallelism</a></li></ul></li><li><a href=/phys52015/notes/mpi/>MPI</a><ul><li><a href=/phys52015/notes/mpi/mpi-ptp/>Point-to-point messaging</a></li><li><a href=/phys52015/notes/mpi/mpi-collectives/>Collectives</a></li><li><a href=/phys52015/notes/mpi/mpi-advanced/>Advanced topics</a></li></ul></li></ul></li><li><a href=/phys52015/coursework/>Coursework: parallel dense linear algebra</a><ul></ul></li><li><a href=/phys52015/resources/>Further resources</a></li><li><a href=/phys52015/acknowledgements/>Acknowledgements</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/phys52015/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Loop parallelism</strong>
<label for=toc-control></label></div></header><article class=markdown><h1 id=openmp-loop-parallelism>OpenMP loop parallelism
<a class=anchor href=#openmp-loop-parallelism>#</a></h1><p>With a parallel region and identification of individual threads, we
can actually parallelise loops &ldquo;by hand&rdquo;.</p><p>Suppose we wish to divide a loop approximately equally between all the
threads, by assigning consecutive blocks of the loop iterations to
consecutive threads.</p><figure style=width:75%><img class=scaled src=https://teaching.wence.uk/phys52015/images/manual/loop-chunking.svg alt="Distribution of 16 loop iterations across five threads."><figcaption><p>Distribution of 16 loop iterations across five threads.</p></figcaption></figure><p>Notice here that the number of iterations is not evenly divisible by
the number of threads, so we&rsquo;ve assigned one extra iteration to
thread0.</p><p>The code that distributes a loop in this way looks something like the below.</p><div class=book-include><div class=book-include-heading><tt>hand-loop.c</tt></div><div class=book-include-download><a href=https://teaching.wence.uk/phys52015/code/openmp-snippets/hand-loop.c>Download</a></div><div class=book-include-content><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;omp.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdio.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e>#include</span> <span style=color:#75715e>&lt;stdlib.h&gt;</span><span style=color:#75715e>
</span><span style=color:#75715e></span><span style=color:#00a8c8>static</span> <span style=color:#00a8c8>inline</span> <span style=color:#00a8c8>int</span> <span style=color:#75af00>min</span><span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>a</span><span style=color:#111>,</span> <span style=color:#00a8c8>int</span> <span style=color:#111>b</span><span style=color:#111>)</span>
<span style=color:#111>{</span>
  <span style=color:#00a8c8>return</span> <span style=color:#111>a</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>b</span> <span style=color:#f92672>?</span> <span style=color:#111>a</span> <span style=color:#111>:</span> <span style=color:#111>b</span><span style=color:#111>;</span>
<span style=color:#111>}</span>

<span style=color:#00a8c8>int</span> <span style=color:#75af00>main</span><span style=color:#111>(</span><span style=color:#00a8c8>void</span><span style=color:#111>)</span>
<span style=color:#111>{</span>
  <span style=color:#00a8c8>const</span> <span style=color:#00a8c8>int</span> <span style=color:#111>N</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>16</span><span style=color:#111>;</span>
  <span style=color:#00a8c8>int</span> <span style=color:#111>a</span><span style=color:#111>[</span><span style=color:#111>N</span><span style=color:#111>];</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
    <span style=color:#75715e>/* Sentinel for unhandled value */</span>
    <span style=color:#111>a</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#111>;</span>
  <span style=color:#111>}</span>
<span style=color:#75715e>#pragma omp parallel default(none) shared(N, a)
</span><span style=color:#75715e></span>  <span style=color:#111>{</span>
    <span style=color:#00a8c8>int</span> <span style=color:#111>tid</span> <span style=color:#f92672>=</span> <span style=color:#111>omp_get_thread_num</span><span style=color:#111>();</span>
    <span style=color:#00a8c8>int</span> <span style=color:#111>nthread</span> <span style=color:#f92672>=</span> <span style=color:#111>omp_get_num_threads</span><span style=color:#111>();</span>

    <span style=color:#00a8c8>int</span> <span style=color:#111>chunk</span> <span style=color:#f92672>=</span> <span style=color:#111>N</span> <span style=color:#f92672>/</span> <span style=color:#111>nthread</span> <span style=color:#f92672>+</span> <span style=color:#111>((</span><span style=color:#111>N</span> <span style=color:#f92672>%</span> <span style=color:#111>nthread</span><span style=color:#111>)</span> <span style=color:#f92672>&gt;</span> <span style=color:#111>tid</span><span style=color:#111>);</span>
    <span style=color:#00a8c8>int</span> <span style=color:#111>start</span> <span style=color:#f92672>=</span> <span style=color:#111>tid</span> <span style=color:#f92672>*</span> <span style=color:#111>(</span><span style=color:#111>N</span> <span style=color:#f92672>/</span> <span style=color:#111>nthread</span><span style=color:#111>)</span> <span style=color:#f92672>+</span> <span style=color:#111>min</span><span style=color:#111>(</span><span style=color:#111>tid</span><span style=color:#111>,</span> <span style=color:#111>N</span> <span style=color:#f92672>%</span> <span style=color:#111>nthread</span><span style=color:#111>);</span>
    <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#111>start</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>start</span> <span style=color:#f92672>+</span> <span style=color:#111>chunk</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
      <span style=color:#111>a</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#111>tid</span><span style=color:#111>;</span>
    <span style=color:#111>}</span>
  <span style=color:#111>}</span>
  <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
    <span style=color:#111>printf</span><span style=color:#111>(</span><span style=color:#d88200>&#34;a[%2d] = %2d</span><span style=color:#8045ff>\n</span><span style=color:#d88200>&#34;</span><span style=color:#111>,</span> <span style=color:#111>i</span><span style=color:#111>,</span> <span style=color:#111>a</span><span style=color:#111>[</span><span style=color:#111>i</span><span style=color:#111>]);</span>
  <span style=color:#111>}</span>
  <span style=color:#00a8c8>return</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span>
<span style=color:#111>}</span>
</code></pre></div></div></div><blockquote class=exercise><h3>Exercise</h3><span>Run this code for a number of threads between 1 and 8. Convince
yourself that it correctly allocates all the loop iterations!</span></blockquote><p>UGH!</p><p>Fortunately, there is a better way<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><h2 id=worksharing-constructs>Worksharing constructs
<a class=anchor href=#worksharing-constructs>#</a></h2><p>Suppose we are in a parallel region, to distribute the work in a loop
amongst the thread team, we use the <code>#pragma omp for</code> directive.</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>void</span> <span style=color:#75af00>foo</span><span style=color:#111>(</span><span style=color:#75715e>/* Some arguments */</span><span style=color:#111>)</span>
<span style=color:#111>{</span>
<span style=color:#75715e>#pragma omp parallel default(none) ...
</span><span style=color:#75715e></span>  <span style=color:#111>{</span>
    <span style=color:#111>...;</span>

    <span style=color:#75715e>/* Loop to parallelise */</span>
    <span style=color:#75715e>#pragma omp for
</span><span style=color:#75715e></span>    <span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#00a8c8>int</span> <span style=color:#111>i</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span><span style=color:#111>;</span> <span style=color:#111>i</span> <span style=color:#f92672>&lt;</span> <span style=color:#111>N</span><span style=color:#111>;</span> <span style=color:#111>i</span><span style=color:#f92672>++</span><span style=color:#111>)</span> <span style=color:#111>{</span>
      <span style=color:#111>...;</span>
    <span style=color:#111>}</span>
  <span style=color:#111>}</span>
<span style=color:#111>}</span>

</code></pre></div><p>This directive does the job of dividing the loop iterations between
the currently active threads. Without the directive, all threads in
the team would execute all iterations.</p><blockquote class="book-hint warning"><span><p>For loop parallelism to be allowable, these loops must obey many of
the same constraints we saw when looking <a href=https://teaching.wence.uk/phys52015/notes/vectorisation/>at vectorisation</a>. Formally, we need the loop to be</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#00a8c8>for</span> <span style=color:#111>(</span><span style=color:#111>var</span> <span style=color:#f92672>=</span> <span style=color:#111>init</span><span style=color:#111>;</span> <span style=color:#111>var</span> <span style=color:#111>logical_op</span> <span style=color:#111>end</span><span style=color:#111>;</span> <span style=color:#111>incr_expr</span><span style=color:#111>)</span>
  <span style=color:#111>...</span>
</code></pre></div><p>Where the <code>logical_op</code> is one of <code>&lt;</code>, <code>&lt;=</code>, <code>></code>, or <code>>=</code> and
<code>incr_expr</code> is an increment expression like <code>var = var + incr</code> (or
similar).</p><p>We are also not allowed to modify <code>var</code> in the loop body.</p></span></blockquote><p>The <code>for</code> directive takes a number of additional clauses that allow us
to control <em>how</em> the loop iterations are divided between threads.</p><p>This pattern of parallel region + loop is so common that there is a
separate directive that encapsulates the two <code>#pragma omp parallel for</code></p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Counterpoint, if you write large libraries using OpenMP you will
probably end up managing the loop parallelism and distribution by
hand in this way anyway. <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/commit/7582099b894ebe59936de6cd4d1e0feb7dea0c4a title="Last modified by Lawrence Mitchell | October 28, 2020" target=_blank rel=noopener><img src=/phys52015/svg/calendar.svg class=book-icon alt=Calendar>
<span>October 28, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/edit/main/site/content/notes/openmp/loop-parallelism.md target=_blank rel=noopener><img src=/phys52015/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>, <a href="https://www.dur.ac.uk/physics/staff/profiles/?mode=staff&id=16712">Christian Arnold</a> & <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/phys52015/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div></main></body></html>