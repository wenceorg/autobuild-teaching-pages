<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Manipulating matrices with collectives #  In this exercise, we&rsquo;ll look at some simple manipulations of matrices with collective operations.
We&rsquo;ll do this with square matrices, where the number of rows (and columns) is equal to the number of processes.
We&rsquo;ll implement three routines:
 printing a matrix by gathering it to a single process and printing there; transposing a matrix; multiplying a matrix against a distributed vector.  For a data distribution, we will use a one-dimensional distribution where each process holds one row."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="MPI: simple collectives"><meta property="og:description" content="Manipulating matrices with collectives #  In this exercise, we&rsquo;ll look at some simple manipulations of matrices with collective operations.
We&rsquo;ll do this with square matrices, where the number of rows (and columns) is equal to the number of processes.
We&rsquo;ll implement three routines:
 printing a matrix by gathering it to a single process and printing there; transposing a matrix; multiplying a matrix against a distributed vector.  For a data distribution, we will use a one-dimensional distribution where each process holds one row."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/phys52015/exercises/mpi-collectives/"><meta property="article:modified_time" content="2020-12-11T17:33:11+00:00"><title>MPI: simple collectives | PHYS52015 – Introduction to HPC</title><link rel=manifest href=/phys52015/manifest.json><link rel=icon href=/phys52015/favicon.png type=image/x-icon><link rel=stylesheet href=/phys52015/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/phys52015/logo.svg alt=Logo><h2><a href=/phys52015>PHYS52015 – Introduction to HPC</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/phys52015/setup/remote/>Remote editing/development</a></li><li><a href=/phys52015/setup/hamilton-quickstart/>Hamilton access & quickstart</a></li><li><a href=/phys52015/setup/byod/>Local setup</a></li><li><a href=/phys52015/setup/configuration/>ssh configuration</a></li><li><a href=/phys52015/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/phys52015/exercises/hello/>Parallel Hello World</a></li><li><a href=/phys52015/exercises/vectorisation-loop/>Vectorisation: loops with conditionals</a></li><li><a href=/phys52015/exercises/vectorisation-stencil/>Vectorisation: stencils</a></li><li><a href=/phys52015/exercises/openmp-loop/>OpenMP: parallel loops</a></li><li><a href=/phys52015/exercises/openmp-stencil/>OpenMP: stencils</a></li><li><a href=/phys52015/exercises/openmp-reduction/>OpenMP: synchronisation</a></li><li><a href=/phys52015/exercises/mpi-ring/>MPI: messages round a ring</a></li><li><a href=/phys52015/exercises/mpi-pi/>MPI: Calculating π</a></li><li><a href=/phys52015/exercises/mpi-ping-pong/>MPI: ping-pong latency</a></li><li><a href=/phys52015/exercises/mpi-collectives/ class=active>MPI: simple collectives</a></li><li><a href=/phys52015/exercises/mpi-stencil/>MPI: domain decomposition and halo exchanges</a></li></ul></li><li><span>Notes</span><ul><li><a href=/phys52015/notes/introduction/>Introduction and motivation</a></li><li><span>Theory & concepts</span><ul><li><a href=/phys52015/notes/theory/scaling-laws/>Parallel scaling laws</a></li><li><a href=/phys52015/notes/theory/hardware-parallelism/>Parallelism in hardware: an overview</a></li><li><a href=/phys52015/notes/theory/concepts/>Parallel patterns</a></li></ul></li><li><a href=/phys52015/notes/vectorisation/>Vectorisation</a><ul><li><a href=/phys52015/notes/vectorisation/compiler/>Compiler autovectorisation</a></li></ul></li><li><a href=/phys52015/notes/openmp/>OpenMP</a><ul><li><a href=/phys52015/notes/openmp/intro/>What is OpenMP?</a></li><li><a href=/phys52015/notes/openmp/loop-parallelism/>Loop parallelism</a></li><li><a href=/phys52015/notes/openmp/collectives/>Collectives</a></li></ul></li><li><a href=/phys52015/notes/mpi/>MPI</a><ul><li><a href=/phys52015/notes/mpi/point-to-point/>Point-to-point messaging in MPI</a></li><li><a href=/phys52015/notes/mpi/point-to-point-nb/>Non-blocking point-to-point messaging</a></li><li><a href=/phys52015/notes/mpi/collectives/>Collectives</a></li><li><a href=/phys52015/notes/mpi/advanced/>Advanced topics</a></li></ul></li></ul></li><li><a href=/phys52015/coursework/>Coursework: parallel dense linear algebra</a><ul></ul></li><li><a href=/phys52015/resources/>Further resources</a></li><li><a href=/phys52015/acknowledgements/>Acknowledgements</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/phys52015/svg/menu.svg class=book-icon alt=Menu></label>
<strong>MPI: simple collectives</strong>
<label for=toc-control></label></div></header><article class=markdown><h1 id=manipulating-matrices-with-collectives>Manipulating matrices with collectives
<a class=anchor href=#manipulating-matrices-with-collectives>#</a></h1><p>In this exercise, we&rsquo;ll look at some simple manipulations of matrices
with collective operations.</p><p>We&rsquo;ll do this with square matrices, where the number of rows (and
columns) is equal to the number of processes.</p><p>We&rsquo;ll implement three routines:</p><ol><li>printing a matrix by gathering it to a single process and printing
there;</li><li>transposing a matrix;</li><li>multiplying a matrix against a distributed vector.</li></ol><p>For a data distribution, we will use a one-dimensional distribution
where each process holds one row.</p><p>I provide a template file <a href=https://teaching.wence.uk/phys52015/code/mpi/collectives/transpose.c><code>matrix.c</code></a> in the <code>code/mpi/collectives</code>
subdirectory.</p><p>It allocates some matrices and sets up the values.</p><blockquote class=exercise><h3>Exercise</h3><span><p>You should
implement the three stubbed-out functions</p><ol><li><code>print_matrix</code></li><li><code>transpose_matrix</code></li><li><code>matrix_vector_product</code></li></ol></span></blockquote><p>I provide a routine to print the vector (so you can see if you&rsquo;ve
implemented the matrix-vector product correctly).</p><h2 id=advanced-optional>Advanced (optional)
<a class=anchor href=#advanced-optional>#</a></h2><p>You could think about how to extend these routines to handle the case
where the matrices continue to be square, but now each process holds
$k$ rows, rather than one row. The matrix is now $kP \times kP$ when
running with $P$ processes. For the vector, each process will now hold
$k$ entries.</p><p>Gathering the matrix for printing and computing the matrix-vector
product are not much more difficult. Transposing becomes rather
harder, because each process needs to send a non-contiguous block of
the input data. You can either rearrange the data so that you send
contiguous blocks of $k\times k$ entries to each process, or use an
MPI derived datatype (see, for example, the EPCC material
<a href=http://www.archer.ac.uk/training/course-material/2019/07/mpi-epcc/slides/L10-derivedtypes.pdf>here</a>).</p><p>Good luck!</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/commit/a2370bb75565866ab1e9d87a04fd7c9f5f322f3e title="Last modified by Lawrence Mitchell | December 11, 2020" target=_blank rel=noopener><img src=/phys52015/svg/calendar.svg class=book-icon alt=Calendar>
<span>December 11, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/edit/main/site/content/exercises/mpi-collectives.md target=_blank rel=noopener><img src=/phys52015/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>, <a href="https://www.dur.ac.uk/physics/staff/profiles/?mode=staff&id=16712">Christian Arnold</a> & <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/phys52015/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div></main></body></html>