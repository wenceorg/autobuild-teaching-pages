<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Parallelisation of a simple loop #  As usual, we&rsquo;ll be running these exercises on Hamilton or COSMA, so remind yourself of how to log in and transfer code if you need to.
Obtaining the code #  We&rsquo;re going to use the same add_numbers code as we did in the previous vectorisation exercise. You should undo your edits from that exercise. If you can&rsquo;t remember what you changed just download and unpack the code again."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="OpenMP: parallel loops"><meta property="og:description" content="Parallelisation of a simple loop #  As usual, we&rsquo;ll be running these exercises on Hamilton or COSMA, so remind yourself of how to log in and transfer code if you need to.
Obtaining the code #  We&rsquo;re going to use the same add_numbers code as we did in the previous vectorisation exercise. You should undo your edits from that exercise. If you can&rsquo;t remember what you changed just download and unpack the code again."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/phys52015/exercises/openmp-loop/"><meta property="article:modified_time" content="2020-12-16T18:30:00+00:00"><title>OpenMP: parallel loops | PHYS52015 – Introduction to HPC</title><link rel=manifest href=/phys52015/manifest.json><link rel=icon href=/phys52015/favicon.png type=image/x-icon><link rel=stylesheet href=/phys52015/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/phys52015/logo.svg alt=Logo><h2><a href=/phys52015>PHYS52015 – Introduction to HPC</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/phys52015/setup/remote/>Remote editing/development</a></li><li><a href=/phys52015/setup/hamilton-quickstart/>Hamilton access & quickstart</a></li><li><a href=/phys52015/setup/byod/>Local setup</a></li><li><a href=/phys52015/setup/configuration/>ssh configuration</a></li><li><a href=/phys52015/setup/unix/>Unix resources</a></li></ul></li><li><span>Exercises</span><ul><li><a href=/phys52015/exercises/hello/>Parallel Hello World</a></li><li><a href=/phys52015/exercises/vectorisation-loop/>Vectorisation: loops with conditionals</a></li><li><a href=/phys52015/exercises/vectorisation-stencil/>Vectorisation: stencils</a></li><li><a href=/phys52015/exercises/openmp-loop/ class=active>OpenMP: parallel loops</a></li><li><a href=/phys52015/exercises/openmp-stencil/>OpenMP: stencils</a></li><li><a href=/phys52015/exercises/openmp-reduction/>OpenMP: synchronisation</a></li><li><a href=/phys52015/exercises/mpi-ring/>MPI: messages round a ring</a></li><li><a href=/phys52015/exercises/mpi-pi/>MPI: Calculating π</a></li><li><a href=/phys52015/exercises/mpi-ping-pong/>MPI: ping-pong latency</a></li><li><a href=/phys52015/exercises/mpi-collectives/>MPI: simple collectives</a></li><li><a href=/phys52015/exercises/mpi-stencil/>MPI: domain decomposition and halo exchanges</a></li></ul></li><li><span>Notes</span><ul><li><a href=/phys52015/notes/introduction/>Introduction and motivation</a></li><li><span>Theory & concepts</span><ul><li><a href=/phys52015/notes/theory/scaling-laws/>Parallel scaling laws</a></li><li><a href=/phys52015/notes/theory/hardware-parallelism/>Parallelism in hardware: an overview</a></li><li><a href=/phys52015/notes/theory/concepts/>Parallel patterns</a></li></ul></li><li><a href=/phys52015/notes/vectorisation/>Vectorisation</a><ul><li><a href=/phys52015/notes/vectorisation/compiler/>Compiler autovectorisation</a></li></ul></li><li><a href=/phys52015/notes/openmp/>OpenMP</a><ul><li><a href=/phys52015/notes/openmp/intro/>What is OpenMP?</a></li><li><a href=/phys52015/notes/openmp/loop-parallelism/>Loop parallelism</a></li><li><a href=/phys52015/notes/openmp/collectives/>Collectives</a></li></ul></li><li><a href=/phys52015/notes/mpi/>MPI</a><ul><li><a href=/phys52015/notes/mpi/point-to-point/>Point-to-point messaging in MPI</a></li><li><a href=/phys52015/notes/mpi/point-to-point-nb/>Non-blocking point-to-point messaging</a></li><li><a href=/phys52015/notes/mpi/collectives/>Collectives</a></li><li><a href=/phys52015/notes/mpi/advanced/>Advanced topics</a></li></ul></li></ul></li><li><a href=/phys52015/coursework/>Coursework: parallel dense linear algebra</a><ul></ul></li><li><a href=/phys52015/resources/>Further resources</a></li><li><a href=/phys52015/acknowledgements/>Acknowledgements</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/phys52015/svg/menu.svg class=book-icon alt=Menu></label>
<strong>OpenMP: parallel loops</strong>
<label for=toc-control></label></div></header><article class=markdown><h1 id=parallelisation-of-a-simple-loop>Parallelisation of a simple loop
<a class=anchor href=#parallelisation-of-a-simple-loop>#</a></h1><p>As usual, we&rsquo;ll be running these exercises on Hamilton or COSMA, so
remind yourself of how to log in and transfer code <a href=https://teaching.wence.uk/phys52015/setup/hamilton-quickstart/>if you need
to</a>.</p><h2 id=obtaining-the-code>Obtaining the code
<a class=anchor href=#obtaining-the-code>#</a></h2><p>We&rsquo;re going to use the same <code>add_numbers</code> code as we did in the
previous <a href=https://teaching.wence.uk/phys52015/exercises/vectorisation-loop/>vectorisation exercise</a>.
You should undo your edits from that exercise. If you can&rsquo;t remember
what you changed just <a href=https://teaching.wence.uk/phys52015/code/add_numbers.tgz>download</a> and
unpack the code again.</p><p>This time, we&rsquo;ll be working in the <code>openmp</code> subdirectory.</p><details><summary>Working from the repository</summary><div class=markdown-inner>If you cloned the <a href=https://github.com/wenceorg/phys52015>repository</a> and have committed your
changes on branches for the previous exercises, just checkout the
<code>main</code> branch again and create a new branch for this exercise.</div></details><h2 id=parallelising-the-loop>Parallelising the loop
<a class=anchor href=#parallelising-the-loop>#</a></h2><blockquote class=exercise><h3>Exercise</h3><span><p>Compile and run the code with OpenMP enabled.</p><p>Try running with different numbers of threads. Does the runtime
change?</p><p>You should use a reasonably large value for <code>N</code>.</p><details><summary>Solution</summary><div class=markdown-inner><p>Remember that to compile with OpenMP, we shuold add the appropriate
flag to the compile command, so we need to add <code>-qopenmp</code> to the
<code>CFLAGS</code> variable in the <code>Makefile</code> and then recompile (<code>make clean</code>
followed by <code>make all</code>).</p><p>Having done that, I see no change in runtime, because the code is not
yet parallelised.</p></div></details></span></blockquote><p>Check the <code>add_numbers</code> routine in <code>add_numbers.c</code>. Annotate it with
appropriate OpenMP pragmas to parallelise the loop.</p><blockquote class=question><h3>Question</h3><span><p>Does the code now have different runtimes when using different numbers
of threads?</p><details><summary>Solution</summary><div class=markdown-inner><p>This code can be parallelised using a simple parallel for.</p><p>In <code>add_numbers.c</code> we annotate the for loop with</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-c data-lang=c><span style=color:#75715e>#pragma omp parallel for default(none) shared(n_numbers, numbers) reduction(+:result) schedule(static)
</span></code></pre></div><p>If I do this, I see that the code now takes less time with fewer
threads.</p></div></details></span></blockquote><h3 id=different-schedules>Different schedules
<a class=anchor href=#different-schedules>#</a></h3><p>Experiment with different <a href=https://teaching.wence.uk/phys52015/notes/openmp/loop-parallelism/#loop-schedules>loop schedules</a>. Which work best? Which work
worst?</p><blockquote class=exercise><h3>Exercise</h3><span><p>Produce a <a href=https://teaching.wence.uk/phys52015/notes/theory/scaling-laws/#amdahl>strong scaling</a> plot
for the computation as a function of the number of threads using the
different schedules you investigated.</p><p>What do you observe?</p><details><summary>Solution</summary><div class=markdown-inner><p>This is what I get for some different schedules when computing on a
vector of one million numbers, I did not run multiple times to avoid
timing variability.</p><figure style=width:75%><img class=scaled src=https://teaching.wence.uk/phys52015/images/auto/add-numbers-scaling.svg alt="Strong scaling of OpenMP parallelisation of add_numbers with different schedule choices."><figcaption><p>Strong scaling of OpenMP parallelisation of add_numbers with different schedule choices.</p></figcaption></figure></div></details></span></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/commit/ea068055e81236889bda89c6cde0db5b18f44297 title="Last modified by Lawrence Mitchell | December 16, 2020" target=_blank rel=noopener><img src=/phys52015/svg/calendar.svg class=book-icon alt=Calendar>
<span>December 16, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/phys52015/edit/main/site/content/exercises/openmp-loop.md target=_blank rel=noopener><img src=/phys52015/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>, <a href="https://www.dur.ac.uk/physics/staff/profiles/?mode=staff&id=16712">Christian Arnold</a> & <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/phys52015/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div></main></body></html>